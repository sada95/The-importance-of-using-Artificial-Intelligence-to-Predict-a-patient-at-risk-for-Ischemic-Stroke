{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(df_dict, heads):\n",
    "    # {key: [], ...}\n",
    "    out = {}\n",
    "    for _key in list(heads):\n",
    "        out[_key] = [df_dict[_key][key] for key in df_dict[_key].keys()]\n",
    "    return out\n",
    "\n",
    "def encode_input(data_range, data):\n",
    "    return data_range.index(data)\n",
    "\n",
    "def preprocess_data(df_list: dict, need_encoded: list, normalize=True) -> np.ndarray:\n",
    "    output = []\n",
    "    data_length = len(df_list['id'])\n",
    "    data_ranges = {k : list(set(df_list[k])) for k in need_encoded}\n",
    "    for i in range(data_length):\n",
    "        item = []\n",
    "        for key in list(df_list.keys())[1:-1]:\n",
    "            if key in need_encoded:\n",
    "                item.append(encode_input(data_ranges[key], df_list[key][i]))\n",
    "            else:\n",
    "                item.append(df_list[key][i])\n",
    "        output.append(item)\n",
    "    inputs_arr = np.array(output)\n",
    "    targets_arr = np.array(df_list['stroke'])\n",
    "    if normalize:\n",
    "        _range = np.max(inputs_arr, axis=0) - np.min(inputs_arr, axis=0)\n",
    "        inputs_arr = (inputs_arr-np.min(inputs_arr, axis=0)) / _range\n",
    "    return inputs_arr, targets_arr\n",
    "\n",
    "def prepare_data(inputs, targets, seed=1001):\n",
    "    positive_mask = targets == 1\n",
    "    negative_mask = targets == 0\n",
    "    n_minimum = min(np.sum(positive_mask), np.sum(negative_mask))\n",
    "    positive_inputs = inputs[positive_mask][0:n_minimum, :]\n",
    "    positive_targets = targets[positive_mask][0:n_minimum]\n",
    "    negative_inputs = inputs[negative_mask][0:n_minimum, :]\n",
    "    negative_targets = targets[negative_mask][0:n_minimum]\n",
    "    inputs = np.concatenate([positive_inputs, negative_inputs]).tolist()\n",
    "    targets = np.concatenate([positive_targets, negative_targets]).tolist()\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(inputs)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(targets)\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "def metrics(y_pred, y_true):\n",
    "    _confusion_matrix = confusion_matrix(y_pred, y_true)\n",
    "    tp = _confusion_matrix[0,0]\n",
    "    fn = _confusion_matrix[1,0]\n",
    "    fp = _confusion_matrix[0,1]\n",
    "    tn = _confusion_matrix[1,1]\n",
    "    # metrics\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fscore = 2*tp/(2*tp + fp + fn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    miss_rate = fn/(tn+tp)\n",
    "    fall_out_rate = fp/(fp+tn)\n",
    "    # return \n",
    "    return [precision, recall, fscore, accuracy, miss_rate, fall_out_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/train_2v.csv'\n",
    "df = pd.read_csv(path)\n",
    "df_clear = df.dropna(axis=0)\n",
    "df_dict = df_clear.to_dict()\n",
    "heads = list(df_dict.keys())\n",
    "df_list = to_list(df_dict, heads)\n",
    "need_encoded = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1, loss: 0.696440060933431, val_acc: 0.49934810951760106\n",
      "epochs: 2, loss: 0.6954947772125403, val_acc: 0.49934810951760106\n",
      "epochs: 3, loss: 0.6944990853468577, val_acc: 0.49934810951760106\n",
      "epochs: 4, loss: 0.6933767460286617, val_acc: 0.49934810951760106\n",
      "epochs: 5, loss: 0.6921489536762238, val_acc: 0.49934810951760106\n",
      "epochs: 6, loss: 0.6907782976826032, val_acc: 0.49934810951760106\n",
      "epochs: 7, loss: 0.6892017275094986, val_acc: 0.49934810951760106\n",
      "epochs: 8, loss: 0.6874086260795593, val_acc: 0.49934810951760106\n",
      "epochs: 9, loss: 0.6854263010124365, val_acc: 0.49934810951760106\n",
      "epochs: 10, loss: 0.6832261867821217, val_acc: 0.5045632333767927\n",
      "epochs: 11, loss: 0.6807494983077049, val_acc: 0.5619295958279009\n",
      "epochs: 12, loss: 0.6778507133324941, val_acc: 0.6310299869621904\n",
      "epochs: 13, loss: 0.6745705232024193, val_acc: 0.6701434159061278\n",
      "epochs: 14, loss: 0.6708908466001352, val_acc: 0.711864406779661\n",
      "epochs: 15, loss: 0.6667930086453756, val_acc: 0.7262059973924381\n",
      "epochs: 16, loss: 0.6621001785000166, val_acc: 0.7196870925684485\n",
      "epochs: 17, loss: 0.6568495817482471, val_acc: 0.7170795306388527\n",
      "epochs: 18, loss: 0.6511246437827746, val_acc: 0.7196870925684485\n",
      "epochs: 19, loss: 0.6449751183390617, val_acc: 0.7222946544980443\n",
      "epochs: 20, loss: 0.6384720591207346, val_acc: 0.7235984354628422\n",
      "epochs: 21, loss: 0.6317386937638124, val_acc: 0.7249022164276402\n",
      "epochs: 22, loss: 0.6249054310222467, val_acc: 0.7249022164276402\n",
      "epochs: 23, loss: 0.6181491414705912, val_acc: 0.7235984354628422\n",
      "epochs: 24, loss: 0.6115459191302458, val_acc: 0.7262059973924381\n",
      "epochs: 25, loss: 0.6053027920424938, val_acc: 0.7249022164276402\n",
      "epochs: 26, loss: 0.5994621030986309, val_acc: 0.727509778357236\n",
      "epochs: 27, loss: 0.5939542849858602, val_acc: 0.7288135593220338\n",
      "epochs: 28, loss: 0.5888782596836487, val_acc: 0.7301173402868318\n",
      "epochs: 29, loss: 0.5842155888676643, val_acc: 0.727509778357236\n",
      "epochs: 30, loss: 0.5799353737384081, val_acc: 0.7249022164276402\n",
      "epochs: 31, loss: 0.576037960126996, val_acc: 0.7262059973924381\n",
      "epochs: 32, loss: 0.5724497673412164, val_acc: 0.727509778357236\n",
      "epochs: 33, loss: 0.5691298029075066, val_acc: 0.7262059973924381\n",
      "epochs: 34, loss: 0.5661072252939144, val_acc: 0.7249022164276402\n",
      "epochs: 35, loss: 0.563254256422321, val_acc: 0.7249022164276402\n",
      "epochs: 36, loss: 0.5605929233133793, val_acc: 0.7262059973924381\n",
      "epochs: 37, loss: 0.5581598325322071, val_acc: 0.7222946544980443\n",
      "epochs: 38, loss: 0.5558768256256977, val_acc: 0.7209908735332464\n",
      "epochs: 39, loss: 0.5536931821455559, val_acc: 0.7222946544980443\n",
      "epochs: 40, loss: 0.551665099337697, val_acc: 0.7209908735332464\n",
      "epochs: 41, loss: 0.5496949516236782, val_acc: 0.7209908735332464\n",
      "epochs: 42, loss: 0.5479134122530619, val_acc: 0.7209908735332464\n",
      "epochs: 43, loss: 0.5461943646272024, val_acc: 0.7196870925684485\n",
      "epochs: 44, loss: 0.5444863165418307, val_acc: 0.7222946544980443\n",
      "epochs: 45, loss: 0.5427407740304867, val_acc: 0.7196870925684485\n",
      "epochs: 46, loss: 0.541117500513792, val_acc: 0.7222946544980443\n",
      "epochs: 47, loss: 0.5396504756063223, val_acc: 0.7249022164276402\n",
      "epochs: 48, loss: 0.5382666060080131, val_acc: 0.7262059973924381\n",
      "epochs: 49, loss: 0.5369620180378357, val_acc: 0.7262059973924381\n",
      "epochs: 50, loss: 0.5357337705790997, val_acc: 0.727509778357236\n",
      "epochs: 51, loss: 0.5345656362672647, val_acc: 0.7288135593220338\n",
      "epochs: 52, loss: 0.533475598320365, val_acc: 0.727509778357236\n",
      "epochs: 53, loss: 0.53239855915308, val_acc: 0.7262059973924381\n",
      "epochs: 54, loss: 0.531380565216144, val_acc: 0.727509778357236\n",
      "epochs: 55, loss: 0.5304295818010966, val_acc: 0.7301173402868318\n",
      "epochs: 56, loss: 0.5295336383084456, val_acc: 0.7301173402868318\n",
      "epochs: 57, loss: 0.528652016694347, val_acc: 0.7314211212516297\n",
      "epochs: 58, loss: 0.5278320405632257, val_acc: 0.7301173402868318\n",
      "epochs: 59, loss: 0.5270536529521147, val_acc: 0.7288135593220338\n",
      "epochs: 60, loss: 0.5263116278996071, val_acc: 0.7301173402868318\n",
      "epochs: 61, loss: 0.5256044107178847, val_acc: 0.7288135593220338\n",
      "epochs: 62, loss: 0.5249261911958456, val_acc: 0.7301173402868318\n",
      "epochs: 63, loss: 0.5242756648610035, val_acc: 0.7314211212516297\n",
      "epochs: 64, loss: 0.5236480757594109, val_acc: 0.7314211212516297\n",
      "epochs: 65, loss: 0.5230558992673954, val_acc: 0.7340286831812256\n",
      "epochs: 66, loss: 0.5224821834514538, val_acc: 0.7340286831812256\n",
      "epochs: 67, loss: 0.5219488081832727, val_acc: 0.7314211212516297\n",
      "epochs: 68, loss: 0.5214290954172611, val_acc: 0.7340286831812256\n",
      "epochs: 69, loss: 0.5209226049482822, val_acc: 0.7340286831812256\n",
      "epochs: 70, loss: 0.5204384252429008, val_acc: 0.7340286831812256\n",
      "epochs: 71, loss: 0.519969372699658, val_acc: 0.7327249022164276\n",
      "epochs: 72, loss: 0.5195112309108177, val_acc: 0.7314211212516297\n",
      "epochs: 73, loss: 0.5190396476536989, val_acc: 0.7314211212516297\n",
      "epochs: 74, loss: 0.5186155401170254, val_acc: 0.7314211212516297\n",
      "epochs: 75, loss: 0.5182056004802386, val_acc: 0.7327249022164276\n",
      "epochs: 76, loss: 0.5178208767126004, val_acc: 0.7340286831812256\n",
      "epochs: 77, loss: 0.5174468979239464, val_acc: 0.7340286831812256\n",
      "epochs: 78, loss: 0.517091262464722, val_acc: 0.7327249022164276\n",
      "epochs: 79, loss: 0.516739958897233, val_acc: 0.7340286831812256\n",
      "epochs: 80, loss: 0.5164074605951706, val_acc: 0.7327249022164276\n",
      "epochs: 81, loss: 0.5160734634846449, val_acc: 0.7340286831812256\n",
      "epochs: 82, loss: 0.51576450218757, val_acc: 0.7353324641460235\n",
      "epochs: 83, loss: 0.5154530815780163, val_acc: 0.7340286831812256\n",
      "epochs: 84, loss: 0.5151582509279251, val_acc: 0.7353324641460235\n",
      "epochs: 85, loss: 0.5148756125320991, val_acc: 0.7366362451108214\n",
      "epochs: 86, loss: 0.5146020036190748, val_acc: 0.7366362451108214\n",
      "epochs: 87, loss: 0.5143659505993128, val_acc: 0.7366362451108214\n",
      "epochs: 88, loss: 0.5140802599489689, val_acc: 0.7353324641460235\n",
      "epochs: 89, loss: 0.5138196827222904, val_acc: 0.7353324641460235\n",
      "epochs: 90, loss: 0.5135905804733435, val_acc: 0.7340286831812256\n",
      "epochs: 91, loss: 0.5133640592296919, val_acc: 0.7340286831812256\n",
      "epochs: 92, loss: 0.5131474900990725, val_acc: 0.7353324641460235\n",
      "epochs: 93, loss: 0.512955604121089, val_acc: 0.7340286831812256\n",
      "epochs: 94, loss: 0.5127338462819656, val_acc: 0.7340286831812256\n",
      "epochs: 95, loss: 0.5125227284928163, val_acc: 0.7340286831812256\n",
      "epochs: 96, loss: 0.5123288910835981, val_acc: 0.7340286831812256\n",
      "epochs: 97, loss: 0.5121445972472429, val_acc: 0.7353324641460235\n",
      "epochs: 98, loss: 0.5119623777767023, val_acc: 0.7353324641460235\n",
      "epochs: 99, loss: 0.5117808276166519, val_acc: 0.7353324641460235\n",
      "epochs: 100, loss: 0.5115972732504209, val_acc: 0.7366362451108214\n",
      "[0.76, 0.6927083333333334, 0.7247956403269755, 0.7366362451108214, 0.2088495575221239, 0.2193211488250653]\n"
     ]
    }
   ],
   "source": [
    "# CNN (resource limitation, only repeat 1)\n",
    "epochs = 100\n",
    "batchsize = 16\n",
    "\n",
    "inputs, targets = preprocess_data(df_list, need_encoded)\n",
    "inputs, targets = prepare_data(inputs, targets)\n",
    "n_samples = inputs.shape[0]\n",
    "tr_inputs = inputs[0:int(n_samples*0.7), :].reshape((-1, 1, 2, 5))\n",
    "tr_targets = targets[0:int(n_samples*0.7)].reshape((-1, 1))\n",
    "te_inputs = inputs[int(n_samples*0.7):, :].reshape((-1, 1, 2, 5))\n",
    "te_targets = targets[int(n_samples*0.7):].reshape((-1, 1))\n",
    "\n",
    "class StrokePred(Dataset):\n",
    "    def __init__(self, inputs, targets) -> None:\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _input = torch.from_numpy(self.inputs[index]).type(torch.float32)\n",
    "        _target = torch.from_numpy(self.targets[index]).type(torch.float32)\n",
    "        return _input, _target\n",
    "\n",
    "class StrokePredModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StrokePredModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=2)\n",
    "\n",
    "        self.linear1 = nn.Linear(32, 16)\n",
    "        self.linear2 = nn.Linear(16, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view((-1, 32))\n",
    "        out = F.relu(self.linear1(out))\n",
    "        return F.sigmoid(self.linear2(out))\n",
    "\n",
    "train_set = StrokePred(tr_inputs, tr_targets)\n",
    "val_set = StrokePred(te_inputs, te_targets)\n",
    "train_loader = DataLoader(train_set, batch_size=batchsize)\n",
    "val_loader = DataLoader(train_set, batch_size=1)\n",
    "\n",
    "model = StrokePredModel()\n",
    "citeration = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    loss_ = 0\n",
    "    acc_ = 0\n",
    "    val_acc = 0\n",
    "    for j, (input_, target_) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(input_)\n",
    "        loss = citeration(out, target_)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.detach().numpy()\n",
    "        pred_ = np.zeros_like(pred)\n",
    "        pred_[pred>0.5] = 1\n",
    "        pred_ = pred_.astype('float')\n",
    "        acc = np.sum(pred_ == target_.numpy()) / batchsize\n",
    "        loss_ += loss.item()\n",
    "        acc_ += acc\n",
    "\n",
    "    model.eval()\n",
    "    for j, (input_, target_) in enumerate(val_loader):\n",
    "        out = model(input_)\n",
    "        pred = out.detach().numpy()\n",
    "        pred_ = np.zeros_like(pred)\n",
    "        pred_[pred>0.5] = 1\n",
    "        pred_ = pred_.astype('float')\n",
    "        acc = np.sum(pred_ == target_.numpy())\n",
    "        val_acc += acc\n",
    "\n",
    "    print(\"epochs: {}, loss: {}, val_acc: {}\".format(\n",
    "        i+1,\n",
    "        loss_ / len(train_loader), \n",
    "        val_acc / len(val_loader)))\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "labels = []\n",
    "for j, (input_, target_) in enumerate(val_loader):\n",
    "    out = model(input_)\n",
    "    pred = out.detach().numpy()\n",
    "    pred_ = np.zeros_like(pred)\n",
    "    pred_[pred>0.5] = 1\n",
    "    pred_ = pred_.astype('float')\n",
    "    preds.append(pred_[0][0])\n",
    "    labels.append(target_.numpy()[0][0])\n",
    "\n",
    "metrics = metrics(preds, labels)\n",
    "# [precision, recall, fscore, accuracy, miss_rate, fall_out_rate]\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f07d5c506dc792c1d17042ce6d63d3539913070c7203ee1d707a2b2ce1ee992d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
